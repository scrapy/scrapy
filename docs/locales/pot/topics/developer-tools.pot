# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008â€“2020, Scrapy developers
# This file is distributed under the same license as the Scrapy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Scrapy 2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-03-03 20:13+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../topics/developer-tools.rst:5
msgid "Using your browser's Developer Tools for scraping"
msgstr ""

#: ../../topics/developer-tools.rst:7
msgid "Here is a general guide on how to use your browser's Developer Tools to ease the scraping process. Today almost all browsers come with built in `Developer Tools`_ and although we will use Firefox in this guide, the concepts are applicable to any other browser."
msgstr ""

#: ../../topics/developer-tools.rst:12
msgid "In this guide we'll introduce the basic tools to use from a browser's Developer Tools by scraping `quotes.toscrape.com`_."
msgstr ""

#: ../../topics/developer-tools.rst:18
msgid "Caveats with inspecting the live browser DOM"
msgstr ""

#: ../../topics/developer-tools.rst:20
msgid "Since Developer Tools operate on a live browser DOM, what you'll actually see when inspecting the page source is not the original HTML, but a modified one after applying some browser clean up and executing Javascript code.  Firefox, in particular, is known for adding ``<tbody>`` elements to tables.  Scrapy, on the other hand, does not modify the original page HTML, so you won't be able to extract any data if you use ``<tbody>`` in your XPath expressions."
msgstr ""

#: ../../topics/developer-tools.rst:27
msgid "Therefore, you should keep in mind the following things:"
msgstr ""

#: ../../topics/developer-tools.rst:29
msgid "Disable Javascript while inspecting the DOM looking for XPaths to be used in Scrapy (in the Developer Tools settings click `Disable JavaScript`)"
msgstr ""

#: ../../topics/developer-tools.rst:32
msgid "Never use full XPath paths, use relative and clever ones based on attributes (such as ``id``, ``class``, ``width``, etc) or any identifying features like ``contains(@href, 'image')``."
msgstr ""

#: ../../topics/developer-tools.rst:36
msgid "Never include ``<tbody>`` elements in your XPath expressions unless you really know what you're doing"
msgstr ""

#: ../../topics/developer-tools.rst:42
msgid "Inspecting a website"
msgstr ""

#: ../../topics/developer-tools.rst:44
msgid "By far the most handy feature of the Developer Tools is the `Inspector` feature, which allows you to inspect the underlying HTML code of any webpage. To demonstrate the Inspector, let's look at the `quotes.toscrape.com`_-site."
msgstr ""

#: ../../topics/developer-tools.rst:49
msgid "On the site we have a total of ten quotes from various authors with specific tags, as well as the Top Ten Tags. Let's say we want to extract all the quotes on this page, without any meta-information about authors, tags, etc."
msgstr ""

#: ../../topics/developer-tools.rst:53
msgid "Instead of viewing the whole source code for the page, we can simply right click on a quote and select ``Inspect Element (Q)``, which opens up the `Inspector`. In it you should see something like this:"
msgstr ""

#: ../../topics/developer-tools.rst:62
msgid "The interesting part for us is this:"
msgstr ""

#: ../../topics/developer-tools.rst:72
msgid "If you hover over the first ``div`` directly above the ``span`` tag highlighted in the screenshot, you'll see that the corresponding section of the webpage gets highlighted as well. So now we have a section, but we can't find our quote text anywhere."
msgstr ""

#: ../../topics/developer-tools.rst:77
msgid "The advantage of the `Inspector` is that it automatically expands and collapses sections and tags of a webpage, which greatly improves readability. You can expand and collapse a tag by clicking on the arrow in front of it or by double clicking directly on the tag. If we expand the ``span`` tag with the ``class= \"text\"`` we will see the quote-text we clicked on. The `Inspector` lets you copy XPaths to selected elements. Let's try it out."
msgstr ""

#: ../../topics/developer-tools.rst:84
msgid "First open the Scrapy shell at http://quotes.toscrape.com/ in a terminal:"
msgstr ""

#: ../../topics/developer-tools.rst:90
msgid "Then, back to your web browser, right-click on the ``span`` tag, select ``Copy > XPath`` and paste it in the Scrapy shell like so:"
msgstr ""

#: ../../topics/developer-tools.rst:100
msgid "Adding ``text()`` at the end we are able to extract the first quote with this basic selector. But this XPath is not really that clever. All it does is go down a desired path in the source code starting from ``html``. So let's see if we can refine our XPath a bit:"
msgstr ""

#: ../../topics/developer-tools.rst:105
msgid "If we check the `Inspector` again we'll see that directly beneath our expanded ``div`` tag we have nine identical ``div`` tags, each with the same attributes as our first. If we expand any of them, we'll see the same structure as with our first quote: Two ``span`` tags and one ``div`` tag. We can expand each ``span`` tag with the ``class=\"text\"`` inside our ``div`` tags and see each quote:"
msgstr ""

#: ../../topics/developer-tools.rst:123
msgid "With this knowledge we can refine our XPath: Instead of a path to follow, we'll simply select all ``span`` tags with the ``class=\"text\"`` by using the `has-class-extension`_:"
msgstr ""

#: ../../topics/developer-tools.rst:133
msgid "And with one simple, cleverer XPath we are able to extract all quotes from the page. We could have constructed a loop over our first XPath to increase the number of the last ``div``, but this would have been unnecessarily complex and by simply constructing an XPath with ``has-class(\"text\")`` we were able to extract all quotes in one line."
msgstr ""

#: ../../topics/developer-tools.rst:139
msgid "The `Inspector` has a lot of other helpful features, such as searching in the source code or directly scrolling to an element you selected. Let's demonstrate a use case:"
msgstr ""

#: ../../topics/developer-tools.rst:143
msgid "Say you want to find the ``Next`` button on the page. Type ``Next`` into the search bar on the top right of the `Inspector`. You should get two results. The first is a ``li`` tag with the ``class=\"next\"``, the second the text of an ``a`` tag. Right click on the ``a`` tag and select ``Scroll into View``. If you hover over the tag, you'll see the button highlighted. From here we could easily create a :ref:`Link Extractor <topics-link-extractors>` to follow the pagination. On a simple site such as this, there may not be the need to find an element visually but the ``Scroll into View`` function can be quite useful on complex sites."
msgstr ""

#: ../../topics/developer-tools.rst:153
msgid "Note that the search bar can also be used to search for and test CSS selectors. For example, you could search for ``span.text`` to find all quote texts. Instead of a full text search, this searches for exactly the ``span`` tag with the ``class=\"text\"`` in the page."
msgstr ""

#: ../../topics/developer-tools.rst:161
msgid "The Network-tool"
msgstr ""

#: ../../topics/developer-tools.rst:162
msgid "While scraping you may come across dynamic webpages where some parts of the page are loaded dynamically through multiple requests. While this can be quite tricky, the `Network`-tool in the Developer Tools greatly facilitates this task. To demonstrate the Network-tool, let's take a look at the page `quotes.toscrape.com/scroll`_."
msgstr ""

#: ../../topics/developer-tools.rst:168
msgid "The page is quite similar to the basic `quotes.toscrape.com`_-page, but instead of the above-mentioned ``Next`` button, the page automatically loads new quotes when you scroll to the bottom. We could go ahead and try out different XPaths directly, but instead we'll check another quite useful command from the Scrapy shell:"
msgstr ""

#: ../../topics/developer-tools.rst:182
msgid "A browser window should open with the webpage but with one crucial difference: Instead of the quotes we just see a greenish bar with the word ``Loading...``."
msgstr ""

#: ../../topics/developer-tools.rst:191
msgid "The ``view(response)`` command let's us view the response our shell or later our spider receives from the server. Here we see that some basic template is loaded which includes the title, the login-button and the footer, but the quotes are missing. This tells us that the quotes are being loaded from a different request than ``quotes.toscrape/scroll``."
msgstr ""

#: ../../topics/developer-tools.rst:198
msgid "If you click on the ``Network`` tab, you will probably only see two entries. The first thing we do is enable persistent logs by clicking on ``Persist Logs``. If this option is disabled, the log is automatically cleared each time you navigate to a different page. Enabling this option is a good default, since it gives us control on when to clear the logs."
msgstr ""

#: ../../topics/developer-tools.rst:205
msgid "If we reload the page now, you'll see the log get populated with six new requests."
msgstr ""

#: ../../topics/developer-tools.rst:213
msgid "Here we see every request that has been made when reloading the page and can inspect each request and its response. So let's find out where our quotes are coming from:"
msgstr ""

#: ../../topics/developer-tools.rst:217
msgid "First click on the request with the name ``scroll``. On the right you can now inspect the request. In ``Headers`` you'll find details about the request headers, such as the URL, the method, the IP-address, and so on. We'll ignore the other tabs and click directly on ``Response``."
msgstr ""

#: ../../topics/developer-tools.rst:222
msgid "What you should see in the ``Preview`` pane is the rendered HTML-code, that is exactly what we saw when we called ``view(response)`` in the shell. Accordingly the ``type`` of the request in the log is ``html``. The other requests have types like ``css`` or ``js``, but what interests us is the one request called ``quotes?page=1`` with the type ``json``."
msgstr ""

#: ../../topics/developer-tools.rst:229
msgid "If we click on this request, we see that the request URL is ``http://quotes.toscrape.com/api/quotes?page=1`` and the response is a JSON-object that contains our quotes. We can also right-click on the request and open ``Open in new tab`` to get a better overview."
msgstr ""

#: ../../topics/developer-tools.rst:239
msgid "With this response we can now easily parse the JSON-object and also request each page to get every quote on the site::"
msgstr ""

#: ../../topics/developer-tools.rst:261
msgid "This spider starts at the first page of the quotes-API. With each response, we parse the ``response.text`` and assign it to ``data``. This lets us operate on the JSON-object like on a Python dictionary. We iterate through the ``quotes`` and print out the ``quote[\"text\"]``. If the handy ``has_next`` element is ``true`` (try loading `quotes.toscrape.com/api/quotes?page=10`_ in your browser or a page-number greater than 10), we increment the ``page`` attribute and ``yield`` a new request, inserting the incremented page-number into our ``url``."
msgstr ""

#: ../../topics/developer-tools.rst:273
msgid "In more complex websites, it could be difficult to easily reproduce the requests, as we could need to add ``headers`` or ``cookies`` to make it work. In those cases you can export the requests in `cURL <https://curl.haxx.se/>`_ format, by right-clicking on each of them in the network tool and using the :meth:`~scrapy.http.Request.from_curl()` method to generate an equivalent request::"
msgstr ""

#: ../../topics/developer-tools.rst:291
msgid "Alternatively, if you want to know the arguments needed to recreate that request you can use the :func:`scrapy.utils.curl.curl_to_request_kwargs` function to get a dictionary with the equivalent arguments."
msgstr ""

#: ../../topics/developer-tools.rst:295
msgid "As you can see, with a few inspections in the `Network`-tool we were able to easily replicate the dynamic requests of the scrolling functionality of the page. Crawling dynamic pages can be quite daunting and pages can be very complex, but it (mostly) boils down to identifying the correct request and replicating it in your spider."
msgstr ""
