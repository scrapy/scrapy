# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008â€“2020, Scrapy developers
# This file is distributed under the same license as the Scrapy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Scrapy 2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-03-03 20:13+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../topics/selectors.rst:5
msgid "Selectors"
msgstr ""

#: ../../topics/selectors.rst:7
msgid ""
"When you're scraping web pages, the most common task you need to perform "
"is to extract data from the HTML source. There are several libraries "
"available to achieve this, such as:"
msgstr ""

#: ../../topics/selectors.rst:11
msgid ""
"`BeautifulSoup`_ is a very popular web scraping library among Python "
"programmers which constructs a Python object based on the structure of "
"the HTML code and also deals with bad markup reasonably well, but it has "
"one drawback: it's slow."
msgstr ""

#: ../../topics/selectors.rst:16
msgid ""
"`lxml`_ is an XML parsing library (which also parses HTML) with a "
"pythonic API based on `ElementTree`_. (lxml is not part of the Python "
"standard library.)"
msgstr ""

#: ../../topics/selectors.rst:20
msgid ""
"Scrapy comes with its own mechanism for extracting data. They're called "
"selectors because they \"select\" certain parts of the HTML document "
"specified either by `XPath`_ or `CSS`_ expressions."
msgstr ""

#: ../../topics/selectors.rst:24
msgid ""
"`XPath`_ is a language for selecting nodes in XML documents, which can "
"also be used with HTML. `CSS`_ is a language for applying styles to HTML "
"documents. It defines selectors to associate those styles with specific "
"HTML elements."
msgstr ""

#: ../../topics/selectors.rst:29
msgid ""
"Scrapy Selectors is a thin wrapper around `parsel`_ library; the purpose "
"of this wrapper is to provide better integration with Scrapy Response "
"objects."
msgstr ""

#: ../../topics/selectors.rst:32
msgid ""
"`parsel`_ is a stand-alone web scraping library which can be used without"
" Scrapy. It uses `lxml`_ library under the hood, and implements an easy "
"API on top of lxml API. It means Scrapy selectors are very similar in "
"speed and parsing accuracy to lxml."
msgstr ""

#: ../../topics/selectors.rst:45 ../../topics/selectors.rst:96
msgid "Using selectors"
msgstr ""

#: ../../topics/selectors.rst:48
msgid "Constructing selectors"
msgstr ""

#: ../../topics/selectors.rst:52
msgid ""
"Response objects expose a :class:`~scrapy.selector.Selector` instance on "
"``.selector`` attribute:"
msgstr ""

#: ../../topics/selectors.rst:58
msgid ""
"Querying responses using XPath and CSS is so common that responses "
"include two more shortcuts: ``response.xpath()`` and ``response.css()``:"
msgstr ""

#: ../../topics/selectors.rst:66
msgid ""
"Scrapy selectors are instances of :class:`~scrapy.selector.Selector` "
"class constructed by passing either :class:`~scrapy.http.TextResponse` "
"object or markup as an unicode string (in ``text`` argument). Usually "
"there is no need to construct Scrapy selectors manually: ``response`` "
"object is available in Spider callbacks, so in most cases it is more "
"convenient to use ``response.css()`` and ``response.xpath()`` shortcuts. "
"By using ``response.selector`` or one of these shortcuts you can also "
"ensure the response body is parsed only once."
msgstr ""

#: ../../topics/selectors.rst:75
msgid ""
"But if required, it is possible to use ``Selector`` directly. "
"Constructing from text:"
msgstr ""

#: ../../topics/selectors.rst:83
msgid ""
"Constructing from response - :class:`~scrapy.http.HtmlResponse` is one of"
" :class:`~scrapy.http.TextResponse` subclasses:"
msgstr ""

#: ../../topics/selectors.rst:92
msgid ""
"``Selector`` automatically chooses the best parsing rules (XML vs HTML) "
"based on input type."
msgstr ""

#: ../../topics/selectors.rst:98
msgid ""
"To explain how to use the selectors we'll use the ``Scrapy shell`` (which"
" provides interactive testing) and an example page located in the Scrapy "
"documentation server:"
msgstr ""

#: ../../topics/selectors.rst:102
msgid "https://docs.scrapy.org/en/latest/_static/selectors-sample1.html"
msgstr ""

#: ../../topics/selectors.rst:106
msgid "For the sake of completeness, here's its full HTML code:"
msgstr ""

#: ../../topics/selectors.rst:113
msgid "First, let's open the shell::"
msgstr ""

#: ../../topics/selectors.rst:117
msgid ""
"Then, after the shell loads, you'll have the response available as "
"``response`` shell variable, and its attached selector in "
"``response.selector`` attribute."
msgstr ""

#: ../../topics/selectors.rst:120
msgid ""
"Since we're dealing with HTML, the selector will automatically use an "
"HTML parser."
msgstr ""

#: ../../topics/selectors.rst:124
msgid ""
"So, by looking at the :ref:`HTML code <topics-selectors-htmlcode>` of "
"that page, let's construct an XPath for selecting the text inside the "
"title tag:"
msgstr ""

#: ../../topics/selectors.rst:130
msgid ""
"To actually extract the textual data, you must call the selector "
"``.get()`` or ``.getall()`` methods, as follows:"
msgstr ""

#: ../../topics/selectors.rst:138
msgid ""
"``.get()`` always returns a single result; if there are several matches, "
"content of a first match is returned; if there are no matches, None is "
"returned. ``.getall()`` returns a list with all results."
msgstr ""

#: ../../topics/selectors.rst:142
msgid ""
"Notice that CSS selectors can select text or attribute nodes using CSS3 "
"pseudo-elements:"
msgstr ""

#: ../../topics/selectors.rst:148
msgid ""
"As you can see, ``.xpath()`` and ``.css()`` methods return a "
":class:`~scrapy.selector.SelectorList` instance, which is a list of new "
"selectors. This API can be used for quickly selecting nested data:"
msgstr ""

#: ../../topics/selectors.rst:159
msgid ""
"If you want to extract only the first matched element, you can call the "
"selector ``.get()`` (or its alias ``.extract_first()`` commonly used in "
"previous Scrapy versions):"
msgstr ""

#: ../../topics/selectors.rst:166
msgid "It returns ``None`` if no element was found:"
msgstr ""

#: ../../topics/selectors.rst:171
msgid ""
"A default return value can be provided as an argument, to be used instead"
" of ``None``:"
msgstr ""

#: ../../topics/selectors.rst:177
msgid ""
"Instead of using e.g. ``'@src'`` XPath it is possible to query for "
"attributes using ``.attrib`` property of a "
":class:`~scrapy.selector.Selector`:"
msgstr ""

#: ../../topics/selectors.rst:187
msgid ""
"As a shortcut, ``.attrib`` is also available on SelectorList directly; it"
" returns attributes for the first matching element:"
msgstr ""

#: ../../topics/selectors.rst:193
msgid ""
"This is most useful when only a single result is expected, e.g. when "
"selecting by id, or selecting unique elements on a web page:"
msgstr ""

#: ../../topics/selectors.rst:199
msgid "Now we're going to get the base URL and some image links:"
msgstr ""

#: ../../topics/selectors.rst:241
msgid "Extensions to CSS Selectors"
msgstr ""

#: ../../topics/selectors.rst:243
msgid ""
"Per W3C standards, `CSS selectors`_ do not support selecting text nodes "
"or attribute values. But selecting these is so essential in a web "
"scraping context that Scrapy (parsel) implements a couple of **non-"
"standard pseudo-elements**:"
msgstr ""

#: ../../topics/selectors.rst:248
msgid "to select text nodes, use ``::text``"
msgstr ""

#: ../../topics/selectors.rst:249
msgid ""
"to select attribute values, use ``::attr(name)`` where *name* is the name"
" of the attribute that you want the value of"
msgstr ""

#: ../../topics/selectors.rst:253
msgid ""
"These pseudo-elements are Scrapy-/Parsel-specific. They will most "
"probably not work with other libraries like `lxml`_ or `PyQuery`_."
msgstr ""

#: ../../topics/selectors.rst:259
msgid "Examples:"
msgstr ""

#: ../../topics/selectors.rst:261
msgid ""
"``title::text`` selects children text nodes of a descendant ``<title>`` "
"element:"
msgstr ""

#: ../../topics/selectors.rst:266
msgid ""
"``*::text`` selects all descendant text nodes of the current selector "
"context:"
msgstr ""

#: ../../topics/selectors.rst:281
msgid ""
"``foo::text`` returns no results if ``foo`` element exists, but contains "
"no text (i.e. text is empty):"
msgstr ""

#: ../../topics/selectors.rst:287
msgid ""
"This means ``.css('foo::text').get()`` could return None even if an "
"element exists. Use ``default=''`` if you always want a string:"
msgstr ""

#: ../../topics/selectors.rst:294
msgid "``a::attr(href)`` selects the *href* attribute value of descendant links:"
msgstr ""

#: ../../topics/selectors.rst:304 ../../topics/selectors.rst:929
#: ../../topics/selectors.rst:969
msgid "See also: :ref:`selecting-attributes`."
msgstr ""

#: ../../topics/selectors.rst:307
msgid ""
"You cannot chain these pseudo-elements. But in practice it would not make"
" much sense: text nodes do not have attributes, and attribute values are "
"string values already and do not have children nodes."
msgstr ""

#: ../../topics/selectors.rst:316
msgid "Nesting selectors"
msgstr ""

#: ../../topics/selectors.rst:318
msgid ""
"The selection methods (``.xpath()`` or ``.css()``) return a list of "
"selectors of the same type, so you can call the selection methods for "
"those selectors too. Here's an example:"
msgstr ""

#: ../../topics/selectors.rst:342
msgid "Selecting element attributes"
msgstr ""

#: ../../topics/selectors.rst:344
msgid ""
"There are several ways to get a value of an attribute. First, one can use"
" XPath syntax:"
msgstr ""

#: ../../topics/selectors.rst:350
msgid ""
"XPath syntax has a few advantages: it is a standard XPath feature, and "
"``@attributes`` can be used in other parts of an XPath expression - e.g. "
"it is possible to filter by attribute value."
msgstr ""

#: ../../topics/selectors.rst:354
msgid ""
"Scrapy also provides an extension to CSS selectors (``::attr(...)``) "
"which allows to get attribute values:"
msgstr ""

#: ../../topics/selectors.rst:360
msgid ""
"In addition to that, there is a ``.attrib`` property of Selector. You can"
" use it if you prefer to lookup attributes in Python code, without using "
"XPaths or CSS extensions:"
msgstr ""

#: ../../topics/selectors.rst:367
msgid ""
"This property is also available on SelectorList; it returns a dictionary "
"with attributes of a first matching element. It is convenient to use when"
" a selector is expected to give a single result (e.g. when selecting by "
"element ID, or when selecting an unique element on a page):"
msgstr ""

#: ../../topics/selectors.rst:377
msgid "``.attrib`` property of an empty SelectorList is empty:"
msgstr ""

#: ../../topics/selectors.rst:383
msgid "Using selectors with regular expressions"
msgstr ""

#: ../../topics/selectors.rst:385
msgid ""
":class:`~scrapy.selector.Selector` also has a ``.re()`` method for "
"extracting data using regular expressions. However, unlike using "
"``.xpath()`` or ``.css()`` methods, ``.re()`` returns a list of unicode "
"strings. So you can't construct nested ``.re()`` calls."
msgstr ""

#: ../../topics/selectors.rst:390
msgid ""
"Here's an example used to extract image names from the :ref:`HTML code "
"<topics-selectors-htmlcode>` above:"
msgstr ""

#: ../../topics/selectors.rst:400
msgid ""
"There's an additional helper reciprocating ``.get()`` (and its alias "
"``.extract_first()``) for ``.re()``, named ``.re_first()``. Use it to "
"extract just the first matching string:"
msgstr ""

#: ../../topics/selectors.rst:410
msgid "extract() and extract_first()"
msgstr ""

#: ../../topics/selectors.rst:412
msgid ""
"If you're a long-time Scrapy user, you're probably familiar with "
"``.extract()`` and ``.extract_first()`` selector methods. Many blog posts"
" and tutorials are using them as well. These methods are still supported "
"by Scrapy, there are **no plans** to deprecate them."
msgstr ""

#: ../../topics/selectors.rst:417
msgid ""
"However, Scrapy usage docs are now written using ``.get()`` and "
"``.getall()`` methods. We feel that these new methods result in a more "
"concise and readable code."
msgstr ""

#: ../../topics/selectors.rst:421
msgid "The following examples show how these methods map to each other."
msgstr ""

#: ../../topics/selectors.rst:423
msgid "``SelectorList.get()`` is the same as ``SelectorList.extract_first()``:"
msgstr ""

#: ../../topics/selectors.rst:430
msgid "``SelectorList.getall()`` is the same as ``SelectorList.extract()``:"
msgstr ""

#: ../../topics/selectors.rst:437
msgid "``Selector.get()`` is the same as ``Selector.extract()``:"
msgstr ""

#: ../../topics/selectors.rst:444
msgid ""
"For consistency, there is also ``Selector.getall()``, which returns a "
"list:"
msgstr ""

#: ../../topics/selectors.rst:449
msgid ""
"So, the main difference is that output of ``.get()`` and ``.getall()`` "
"methods is more predictable: ``.get()`` always returns a single result, "
"``.getall()`` always returns a list of all extracted results. With "
"``.extract()`` method it was not always obvious if a result is a list or "
"not; to get a single result either ``.extract()`` or ``.extract_first()``"
" should be called."
msgstr ""

#: ../../topics/selectors.rst:459
msgid "Working with XPaths"
msgstr ""

#: ../../topics/selectors.rst:461
msgid ""
"Here are some tips which may help you to use XPath with Scrapy selectors "
"effectively. If you are not much familiar with XPath yet, you may want to"
" take a look first at this `XPath tutorial`_."
msgstr ""

#: ../../topics/selectors.rst:466
msgid "Some of the tips are based on `this post from ScrapingHub's blog`_."
msgstr ""

#: ../../topics/selectors.rst:475
msgid "Working with relative XPaths"
msgstr ""

#: ../../topics/selectors.rst:477
msgid ""
"Keep in mind that if you are nesting selectors and use an XPath that "
"starts with ``/``, that XPath will be absolute to the document and not "
"relative to the ``Selector`` you're calling it from."
msgstr ""

#: ../../topics/selectors.rst:481
msgid ""
"For example, suppose you want to extract all ``<p>`` elements inside "
"``<div>`` elements. First, you would get all ``<div>`` elements:"
msgstr ""

#: ../../topics/selectors.rst:486
msgid ""
"At first, you may be tempted to use the following approach, which is "
"wrong, as it actually extracts all ``<p>`` elements from the document, "
"not only those inside ``<div>`` elements:"
msgstr ""

#: ../../topics/selectors.rst:493
msgid ""
"This is the proper way to do it (note the dot prefixing the ``.//p`` "
"XPath):"
msgstr ""

#: ../../topics/selectors.rst:498
msgid "Another common case would be to extract all direct ``<p>`` children:"
msgstr ""

#: ../../topics/selectors.rst:503
msgid ""
"For more details about relative XPaths see the `Location Paths`_ section "
"in the XPath specification."
msgstr ""

#: ../../topics/selectors.rst:509
msgid "When querying by class, consider using CSS"
msgstr ""

#: ../../topics/selectors.rst:511
msgid ""
"Because an element can contain multiple CSS classes, the XPath way to "
"select elements by class is the rather verbose::"
msgstr ""

#: ../../topics/selectors.rst:516
msgid ""
"If you use ``@class='someclass'`` you may end up missing elements that "
"have other classes, and if you just use ``contains(@class, 'someclass')``"
" to make up for that you may end up with more elements that you want, if "
"they have a different class name that shares the string ``someclass``."
msgstr ""

#: ../../topics/selectors.rst:521
msgid ""
"As it turns out, Scrapy selectors allow you to chain selectors, so most "
"of the time you can just select by class using CSS and then switch to "
"XPath when needed:"
msgstr ""

#: ../../topics/selectors.rst:529
msgid ""
"This is cleaner than using the verbose XPath trick shown above. Just "
"remember to use the ``.`` in the XPath expressions that will follow."
msgstr ""

#: ../../topics/selectors.rst:533
msgid "Beware of the difference between //node[1] and (//node)[1]"
msgstr ""

#: ../../topics/selectors.rst:535
msgid ""
"``//node[1]`` selects all the nodes occurring first under their "
"respective parents."
msgstr ""

#: ../../topics/selectors.rst:537
msgid ""
"``(//node)[1]`` selects all the nodes in the document, and then gets only"
" the first of them."
msgstr ""

#: ../../topics/selectors.rst:539 ../../topics/selectors.rst:585
msgid "Example:"
msgstr ""

#: ../../topics/selectors.rst:555
msgid "This gets all first ``<li>``  elements under whatever it is its parent:"
msgstr ""

#: ../../topics/selectors.rst:560
msgid "And this gets the first ``<li>``  element in the whole document:"
msgstr ""

#: ../../topics/selectors.rst:565
msgid "This gets all first ``<li>``  elements under an ``<ul>``  parent:"
msgstr ""

#: ../../topics/selectors.rst:570
msgid ""
"And this gets the first ``<li>``  element under an ``<ul>``  parent in "
"the whole document:"
msgstr ""

#: ../../topics/selectors.rst:576
msgid "Using text nodes in a condition"
msgstr ""

#: ../../topics/selectors.rst:578
msgid ""
"When you need to use the text content as argument to an `XPath string "
"function`_, avoid using ``.//text()`` and use just ``.`` instead."
msgstr ""

#: ../../topics/selectors.rst:581
msgid ""
"This is because the expression ``.//text()`` yields a collection of text "
"elements -- a *node-set*. And when a node-set is converted to a string, "
"which happens when it is passed as argument to a string function like "
"``contains()`` or ``starts-with()``, it results in the text for the first"
" element only."
msgstr ""

#: ../../topics/selectors.rst:590
msgid "Converting a *node-set* to string:"
msgstr ""

#: ../../topics/selectors.rst:597
msgid ""
"A *node* converted to a string, however, puts together the text of itself"
" plus of all its descendants:"
msgstr ""

#: ../../topics/selectors.rst:604
msgid "So, using the ``.//text()`` node-set won't select anything in this case:"
msgstr ""

#: ../../topics/selectors.rst:609
msgid "But using the ``.`` to mean the node, works:"
msgstr ""

#: ../../topics/selectors.rst:619
msgid "Variables in XPath expressions"
msgstr ""

#: ../../topics/selectors.rst:621
msgid ""
"XPath allows you to reference variables in your XPath expressions, using "
"the ``$somevariable`` syntax. This is somewhat similar to parameterized "
"queries or prepared statements in the SQL world where you replace some "
"arguments in your queries with placeholders like ``?``, which are then "
"substituted with values passed with the query."
msgstr ""

#: ../../topics/selectors.rst:627
msgid ""
"Here's an example to match an element based on its \"id\" attribute "
"value, without hard-coding it (that was shown previously):"
msgstr ""

#: ../../topics/selectors.rst:634
msgid ""
"Here's another example, to find the \"id\" attribute of a ``<div>`` tag "
"containing five ``<a>`` children (here we pass the value ``5`` as an "
"integer):"
msgstr ""

#: ../../topics/selectors.rst:640
msgid ""
"All variable references must have a binding value when calling "
"``.xpath()`` (otherwise you'll get a ``ValueError: XPath error:`` "
"exception). This is done by passing as many named arguments as necessary."
msgstr ""

#: ../../topics/selectors.rst:644
msgid ""
"`parsel`_, the library powering Scrapy selectors, has more details and "
"examples on `XPath variables`_."
msgstr ""

#: ../../topics/selectors.rst:653
msgid "Removing namespaces"
msgstr ""

#: ../../topics/selectors.rst:655
msgid ""
"When dealing with scraping projects, it is often quite convenient to get "
"rid of namespaces altogether and just work with element names, to write "
"more simple/convenient XPaths. You can use the "
":meth:`Selector.remove_namespaces` method for that."
msgstr ""

#: ../../topics/selectors.rst:660
msgid ""
"Let's show an example that illustrates this with the Python Insider blog "
"atom feed."
msgstr ""

#: ../../topics/selectors.rst:664
msgid "First, we open the shell with the url we want to scrape::"
msgstr ""

#: ../../topics/selectors.rst:668
msgid "This is how the file starts::"
msgstr ""

#: ../../topics/selectors.rst:681
msgid ""
"You can see several namespace declarations including a default "
"\"http://www.w3.org/2005/Atom\" and another one using the \"gd:\" prefix "
"for \"http://schemas.google.com/g/2005\"."
msgstr ""

#: ../../topics/selectors.rst:687
msgid ""
"Once in the shell we can try selecting all ``<link>`` objects and see "
"that it doesn't work (because the Atom XML namespace is obfuscating those"
" nodes):"
msgstr ""

#: ../../topics/selectors.rst:693
msgid ""
"But once we call the :meth:`Selector.remove_namespaces` method, all nodes"
" can be accessed directly by their names:"
msgstr ""

#: ../../topics/selectors.rst:702
msgid ""
"If you wonder why the namespace removal procedure isn't always called by "
"default instead of having to call it manually, this is because of two "
"reasons, which, in order of relevance, are:"
msgstr ""

#: ../../topics/selectors.rst:706
msgid ""
"Removing namespaces requires to iterate and modify all nodes in the "
"document, which is a reasonably expensive operation to perform by default"
" for all documents crawled by Scrapy"
msgstr ""

#: ../../topics/selectors.rst:710
msgid ""
"There could be some cases where using namespaces is actually required, in"
" case some element names clash between namespaces. These cases are very "
"rare though."
msgstr ""

#: ../../topics/selectors.rst:716
msgid "Using EXSLT extensions"
msgstr ""

#: ../../topics/selectors.rst:718
msgid ""
"Being built atop `lxml`_, Scrapy selectors support some `EXSLT`_ "
"extensions and come with these pre-registered namespaces to use in XPath "
"expressions:"
msgstr ""

#: ../../topics/selectors.rst:723
msgid "prefix"
msgstr ""

#: ../../topics/selectors.rst:723
msgid "namespace"
msgstr ""

#: ../../topics/selectors.rst:723
msgid "usage"
msgstr ""

#: ../../topics/selectors.rst:725
msgid "re"
msgstr ""

#: ../../topics/selectors.rst:725
msgid "\\http://exslt.org/regular-expressions"
msgstr ""

#: ../../topics/selectors.rst:725
msgid "`regular expressions`_"
msgstr ""

#: ../../topics/selectors.rst:726
msgid "set"
msgstr ""

#: ../../topics/selectors.rst:726
msgid "\\http://exslt.org/sets"
msgstr ""

#: ../../topics/selectors.rst:726
msgid "`set manipulation`_"
msgstr ""

#: ../../topics/selectors.rst:730
msgid "Regular expressions"
msgstr ""

#: ../../topics/selectors.rst:732
msgid ""
"The ``test()`` function, for example, can prove quite useful when XPath's"
" ``starts-with()`` or ``contains()`` are not sufficient."
msgstr ""

#: ../../topics/selectors.rst:735
msgid ""
"Example selecting links in list item with a \"class\" attribute ending "
"with a digit:"
msgstr ""

#: ../../topics/selectors.rst:755
msgid ""
"C library ``libxslt`` doesn't natively support EXSLT regular expressions "
"so `lxml`_'s implementation uses hooks to Python's ``re`` module. Thus, "
"using regexp functions in your XPath expressions may add a small "
"performance penalty."
msgstr ""

#: ../../topics/selectors.rst:761
msgid "Set operations"
msgstr ""

#: ../../topics/selectors.rst:763
msgid ""
"These can be handy for excluding parts of a document tree before "
"extracting text elements for example."
msgstr ""

#: ../../topics/selectors.rst:766
msgid ""
"Example extracting microdata (sample content taken from "
"https://schema.org/Product) with groups of itemscopes and corresponding "
"itemprops::"
msgstr ""

#: ../../topics/selectors.rst:850
msgid ""
"Here we first iterate over ``itemscope`` elements, and for each one, we "
"look for all ``itemprops`` elements and exclude those that are themselves"
" inside another ``itemscope``."
msgstr ""

#: ../../topics/selectors.rst:859
msgid "Other XPath extensions"
msgstr ""

#: ../../topics/selectors.rst:861
msgid ""
"Scrapy selectors also provide a sorely missed XPath extension function "
"``has-class`` that returns ``True`` for nodes that have all of the "
"specified HTML classes."
msgstr ""

#: ../../topics/selectors.rst:867
msgid "For the following HTML::"
msgstr ""

#: ../../topics/selectors.rst:876
msgid "You can use it like this:"
msgstr ""

#: ../../topics/selectors.rst:886
msgid ""
"So XPath ``//p[has-class(\"foo\", \"bar-baz\")]`` is roughly equivalent "
"to CSS ``p.foo.bar-baz``.  Please note, that it is slower in most of the "
"cases, because it's a pure-Python function that's invoked for every node "
"in question whereas the CSS lookup is translated into XPath and thus runs"
" more efficiently, so performance-wise its uses are limited to situations"
" that are not easily described with CSS selectors."
msgstr ""

#: ../../topics/selectors.rst:893
msgid "Parsel also simplifies adding your own XPath extensions."
msgstr ""

#: of parsel.xpathfuncs.set_xpathfunc:1
msgid "Register a custom extension function to use in XPath expressions."
msgstr ""

#: of parsel.xpathfuncs.set_xpathfunc:3
msgid ""
"The function ``func`` registered under ``fname`` identifier will be "
"called for every matching node, being passed a ``context`` parameter as "
"well as any parameters passed from the corresponding XPath expression."
msgstr ""

#: of parsel.xpathfuncs.set_xpathfunc:7
msgid "If ``func`` is ``None``, the extension function will be removed."
msgstr ""

#: of parsel.xpathfuncs.set_xpathfunc:9
msgid "See more `in lxml documentation`_."
msgstr ""

#: ../../topics/selectors.rst:901
msgid "Built-in Selectors reference"
msgstr ""

#: ../../topics/selectors.rst:907
msgid "Selector objects"
msgstr ""

#: of scrapy.selector.Selector:1
msgid ""
"An instance of :class:`Selector` is a wrapper over response to select "
"certain parts of its content."
msgstr ""

#: of scrapy.selector.Selector:4
msgid ""
"``response`` is an :class:`~scrapy.http.HtmlResponse` or an "
":class:`~scrapy.http.XmlResponse` object that will be used for selecting "
"and extracting data."
msgstr ""

#: of scrapy.selector.Selector:8
msgid ""
"``text`` is a unicode string or utf-8 encoded text for cases when a "
"``response`` isn't available. Using ``text`` and ``response`` together is"
" undefined behavior."
msgstr ""

#: of scrapy.selector.Selector:12
msgid ""
"``type`` defines the selector type, it can be ``\"html\"``, ``\"xml\"`` "
"or ``None`` (default)."
msgstr ""

#: of scrapy.selector.Selector:15
msgid ""
"If ``type`` is ``None``, the selector automatically chooses the best type"
" based on ``response`` type (see below), or defaults to ``\"html\"`` in "
"case it is used together with ``text``."
msgstr ""

#: of scrapy.selector.Selector:19
msgid ""
"If ``type`` is ``None`` and a ``response`` is passed, the selector type "
"is inferred from the response type as follows:"
msgstr ""

#: of scrapy.selector.Selector:22
msgid "``\"html\"`` for :class:`~scrapy.http.HtmlResponse` type"
msgstr ""

#: of scrapy.selector.Selector:23
msgid "``\"xml\"`` for :class:`~scrapy.http.XmlResponse` type"
msgstr ""

#: of scrapy.selector.Selector:24
msgid "``\"html\"`` for anything else"
msgstr ""

#: of scrapy.selector.Selector:26
msgid ""
"Otherwise, if ``type`` is set, the selector type will be forced and no "
"detection will occur."
msgstr ""

#: of scrapy.selector.Selector.xpath:1
msgid ""
"Find nodes matching the xpath ``query`` and return the result as a "
":class:`SelectorList` instance with all elements flattened. List elements"
" implement :class:`Selector` interface too."
msgstr ""

#: of scrapy.selector.Selector.xpath:5
msgid "``query`` is a string containing the XPATH query to apply."
msgstr ""

#: of scrapy.selector.Selector.xpath:7 scrapy.selector.SelectorList.xpath:6
msgid ""
"``namespaces`` is an optional ``prefix: namespace-uri`` mapping (dict) "
"for additional prefixes to those registered with "
"``register_namespace(prefix, uri)``. Contrary to "
"``register_namespace()``, these prefixes are not saved for future calls."
msgstr ""

#: of scrapy.selector.Selector.xpath:12 scrapy.selector.SelectorList.xpath:11
msgid ""
"Any additional named arguments can be used to pass values for XPath "
"variables in the XPath expression, e.g.::"
msgstr ""

#: ../../topics/selectors.rst:915
msgid "For convenience, this method can be called as ``response.xpath()``"
msgstr ""

#: of scrapy.selector.Selector.css:1
msgid "Apply the given CSS selector and return a :class:`SelectorList` instance."
msgstr ""

#: of scrapy.selector.Selector.css:3
msgid "``query`` is a string containing the CSS selector to apply."
msgstr ""

#: of scrapy.selector.Selector.css:5
msgid ""
"In the background, CSS queries are translated into XPath queries using "
"`cssselect`_ library and run ``.xpath()`` method."
msgstr ""

#: ../../topics/selectors.rst:921
msgid "For convenience, this method can be called as ``response.css()``"
msgstr ""

#: of scrapy.selector.Selector.get:1
msgid ""
"Serialize and return the matched nodes in a single unicode string. "
"Percent encoded content is unquoted."
msgstr ""

#: ../../topics/selectors.rst:925 ../../topics/selectors.rst:957
#: ../../topics/selectors.rst:961
msgid "See also: :ref:`old-extraction-api`"
msgstr ""

#: of scrapy.selector.Selector.attrib:1
msgid "Return the attributes dictionary for underlying element."
msgstr ""

#: of scrapy.selector.Selector.re:1
msgid ""
"Apply the given regex and return a list of unicode strings with the "
"matches."
msgstr ""

#: of scrapy.selector.Selector.re:4
msgid ""
"``regex`` can be either a compiled regular expression or a string which "
"will be compiled to a regular expression using ``re.compile(regex)``."
msgstr ""

#: of scrapy.selector.Selector.re:7 scrapy.selector.Selector.re_first:5
msgid ""
"By default, character entity references are replaced by their "
"corresponding character (except for ``&amp;`` and ``&lt;``). Passing "
"``replace_entities`` as ``False`` switches off these replacements."
msgstr ""

#: of scrapy.selector.Selector.re_first:1
msgid ""
"Apply the given regex and return the first unicode string which matches. "
"If there is no match, return the default value (``None`` if the argument "
"is not provided)."
msgstr ""

#: of scrapy.selector.Selector.register_namespace:1
msgid ""
"Register the given namespace to be used in this :class:`Selector`. "
"Without registering namespaces you can't select or extract data from non-"
"standard namespaces. See :ref:`selector-examples-xml`."
msgstr ""

#: of scrapy.selector.Selector.remove_namespaces:1
msgid ""
"Remove all namespaces, allowing to traverse the document using namespace-"
"less xpaths. See :ref:`removing-namespaces`."
msgstr ""

#: of scrapy.selector.Selector.__bool__:1
msgid ""
"Return ``True`` if there is any real content selected or ``False`` "
"otherwise.  In other words, the boolean value of a :class:`Selector` is "
"given by the contents it selects."
msgstr ""

#: of scrapy.selector.Selector.getall:1
msgid ""
"Serialize and return the matched node in a 1-element list of unicode "
"strings."
msgstr ""

#: ../../topics/selectors.rst:943
msgid ""
"This method is added to Selector for consistency; it is more useful with "
"SelectorList. See also: :ref:`old-extraction-api`"
msgstr ""

#: ../../topics/selectors.rst:947
msgid "SelectorList objects"
msgstr ""

#: of scrapy.selector.SelectorList:1
msgid ""
"The :class:`SelectorList` class is a subclass of the builtin ``list`` "
"class, which provides a few additional methods."
msgstr ""

#: of scrapy.selector.SelectorList.xpath:1
msgid ""
"Call the ``.xpath()`` method for each element in this list and return "
"their results flattened as another :class:`SelectorList`."
msgstr ""

#: of scrapy.selector.SelectorList.xpath:4
msgid "``query`` is the same argument as the one in :meth:`Selector.xpath`"
msgstr ""

#: of scrapy.selector.SelectorList.css:1
msgid ""
"Call the ``.css()`` method for each element in this list and return their"
" results flattened as another :class:`SelectorList`."
msgstr ""

#: of scrapy.selector.SelectorList.css:4
msgid "``query`` is the same argument as the one in :meth:`Selector.css`"
msgstr ""

#: of scrapy.selector.SelectorList.getall:1
msgid ""
"Call the ``.get()`` method for each element is this list and return their"
" results flattened, as a list of unicode strings."
msgstr ""

#: of scrapy.selector.SelectorList.get:1
msgid ""
"Return the result of ``.get()`` for the first element in this list. If "
"the list is empty, return the default value."
msgstr ""

#: of scrapy.selector.SelectorList.re:1
msgid ""
"Call the ``.re()`` method for each element in this list and return their "
"results flattened, as a list of unicode strings."
msgstr ""

#: of scrapy.selector.SelectorList.re:4 scrapy.selector.SelectorList.re_first:6
msgid ""
"By default, character entity references are replaced by their "
"corresponding character (except for ``&amp;`` and ``&lt;``. Passing "
"``replace_entities`` as ``False`` switches off these replacements."
msgstr ""

#: of scrapy.selector.SelectorList.re_first:1
msgid ""
"Call the ``.re()`` method for the first element in this list and return "
"the result in an unicode string. If the list is empty or the regex "
"doesn't match anything, return the default value (``None`` if the "
"argument is not provided)."
msgstr ""

#: of scrapy.selector.SelectorList.attrib:1
msgid ""
"Return the attributes dictionary for the first element. If the list is "
"empty, return an empty dict."
msgstr ""

#: ../../topics/selectors.rst:974
msgid "Examples"
msgstr ""

#: ../../topics/selectors.rst:979
msgid "Selector examples on HTML response"
msgstr ""

#: ../../topics/selectors.rst:981
msgid ""
"Here are some :class:`Selector` examples to illustrate several concepts. "
"In all cases, we assume there is already a :class:`Selector` instantiated"
" with a :class:`~scrapy.http.HtmlResponse` object like this::"
msgstr ""

#: ../../topics/selectors.rst:987
msgid ""
"Select all ``<h1>`` elements from an HTML response body, returning a list"
" of :class:`Selector` objects (i.e. a :class:`SelectorList` object)::"
msgstr ""

#: ../../topics/selectors.rst:992
msgid ""
"Extract the text of all ``<h1>`` elements from an HTML response body, "
"returning a list of unicode strings::"
msgstr ""

#: ../../topics/selectors.rst:998
msgid "Iterate over all ``<p>`` tags and print their class attribute::"
msgstr ""

#: ../../topics/selectors.rst:1007
msgid "Selector examples on XML response"
msgstr ""

#: ../../topics/selectors.rst:1009
msgid ""
"Here are some examples to illustrate concepts for :class:`Selector` "
"objects instantiated with an :class:`~scrapy.http.XmlResponse` object::"
msgstr ""

#: ../../topics/selectors.rst:1014
msgid ""
"Select all ``<product>`` elements from an XML response body, returning a "
"list of :class:`Selector` objects (i.e. a :class:`SelectorList` object)::"
msgstr ""

#: ../../topics/selectors.rst:1019
msgid ""
"Extract all prices from a `Google Base XML feed`_ which requires "
"registering a namespace::"
msgstr ""

